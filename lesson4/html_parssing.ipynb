{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lxml.etree._ElementTree object at 0x000001EE89195EC0>\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "# import requests\n",
    "\n",
    "tree =etree.parse(\"src/web_page.html\")\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraping course.\n",
      "GeekBrain's link: Developer\n"
     ]
    }
   ],
   "source": [
    "title_element = tree.find(\"body/ul/li\")\n",
    "print(title_element.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Element li at 0x1ee896530c0>, <Element li at 0x1ee89653800>]\n",
      "Data scraping course.\n",
      "GeekBrain's link: Developer\n"
     ]
    }
   ],
   "source": [
    "list_item = tree.findall(\"body/ul/li\")\n",
    "print(list_item)\n",
    "for li in list_item: \n",
    "    a = li.find(\"a\")\n",
    "    if a is not None:\n",
    "        print(f'{li.text.strip()} {a.text}')\n",
    "    else:\n",
    "        print(li.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is title of the page\n",
      "Hello GeekBrains\n"
     ]
    }
   ],
   "source": [
    "title_element = tree.xpath(\"//title\")\n",
    "print(title_element[0].text)\n",
    "title_element = tree.xpath(\"//p/text()\")[0]\n",
    "print(title_element)\n",
    "list_item = tree.findall(\"body/ul/li\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<li id=\"myID\">Data scraping course.</li>\\n'\n",
      "b'<li class=\"myClass\">GeekBrain\\'s link:\\n<a href=\"https://gb.ru/geek_university/developer\">Developer</a>\\n</li>\\n'\n"
     ]
    }
   ],
   "source": [
    "list_item = tree.xpath(\"//li\")\n",
    "for li in list_item:\n",
    "    print(etree.tostring(li))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '\\n', 'This is title of the page', '\\n', '\\n', '\\n', 'Hello GeekBrains', '\\n', '\\n', 'Data scraping course.', '\\n', \"GeekBrain's link:\\n\", 'Developer', '\\n', '\\n', '\\n', '\\n']\n",
      "['\\n', '\\n', 'This is title of the page', '\\n', '\\n', '\\n', 'Hello GeekBrains', '\\n', '\\n', 'Data scraping course.', '\\n', \"GeekBrain's link:\\n\", 'Developer', '\\n', '\\n', '\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "list_item = tree.xpath(\"//li\")\n",
    "for li in list_item:\n",
    "    text = tree.xpath('//text()')\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', 'This is title of the page', '', '', '', 'Hello GeekBrains', '', '', 'Data scraping course.', '', \"GeekBrain's link:\", 'Developer', '', '', '', '']\n",
      "['', '', 'This is title of the page', '', '', '', 'Hello GeekBrains', '', '', 'Data scraping course.', '', \"GeekBrain's link:\", 'Developer', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "list_item = tree.xpath(\"//li\")\n",
    "for li in list_item:\n",
    "    text = map(str.strip, li.xpath(\"//text()\"))\n",
    "    print(list(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is title of the pageHello GeekBrainsData scraping course.GeekBrain's link:Developer\n",
      "This is title of the pageHello GeekBrainsData scraping course.GeekBrain's link:Developer\n"
     ]
    }
   ],
   "source": [
    "list_item = tree.xpath(\"//ul/descendant::li\")\n",
    "for li in list_item:\n",
    "    text = ''.join(map(str.strip, li.xpath(\"//text()\")))\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is title of the page\n"
     ]
    }
   ],
   "source": [
    "html = tree.getroot()\n",
    "title_element = html.cssselect(\"title\")\n",
    "print(title_element[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraping course.\n"
     ]
    }
   ],
   "source": [
    "html = tree.getroot()\n",
    "title_element = html.cssselect(\"li\")\n",
    "print(title_element[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "from lxml import html\n",
    "\n",
    "ua = UserAgent()\n",
    "url = 'https://www.imdb.com/chart/moviemeter/?ref_=nv_mv_mpm'\n",
    "headers = {'User-Agent': ua.random}\n",
    "session = requests.Session()\n",
    "response = session.get(url, headers=headers)\n",
    "tree = html.fromstring(html=response.content)\n",
    "movies = tree.xpath('.//div[contains(@class, \"cli-title\")]/a/h3/text()')\n",
    "# print(response.status_code)\n",
    "\n",
    "\n",
    "# try:\n",
    "    m = {\n",
    "    'name': movie.xpath(\".//div[contains(@class, 'cli-title')]/a/h3/text()\")[0],\n",
    "    'release_year': movie.xpath(\".//div[contains(@class, 'cli-title-metadata')]/span/text()\")[0],\n",
    "    'position': movie.xpath(\".//div[contains(@class, 'meter-const-ranking')]/text()\")[0],\n",
    "    'titlemeter': movie.xpath(\".//div[contains(@class, 'meter-const-ranking')]/span/svg[contains(@class, 'sc-db6887cf-0')]/@class\")[0],\n",
    "    'position_change': movie.xpath(\".//div[contains(@class, 'meter-const-ranking')]/span/text()\")[0]\n",
    "    }\n",
    "#     all_movies.append(m)\n",
    "# except IndexError:\n",
    "# # Обрабатываем случаи, когда какой-то элемент не был найден\n",
    "#     continue\n",
    "\n",
    "#     pprint(all_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m all_movies \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m movie \u001b[38;5;129;01min\u001b[39;00m movies:\n\u001b[0;32m     14\u001b[0m     m \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mmovie\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxpath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.//div[contains(@class, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcli-title\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)]/a/h3/text()\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_year\u001b[39m\u001b[38;5;124m'\u001b[39m: movie\u001b[38;5;241m.\u001b[39mxpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.//div[contains(@class, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcli-title-metadata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)]/span/text()\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m: movie\u001b[38;5;241m.\u001b[39mxpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.//div[contains(@class, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeter-const-ranking\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)]/text()\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitlemeter\u001b[39m\u001b[38;5;124m'\u001b[39m: movie\u001b[38;5;241m.\u001b[39mxpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.//div[contains(@class, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeter-const-ranking\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)]/span/svg[contains(@class, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msc-db6887cf-0\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)]/@class\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition_change\u001b[39m\u001b[38;5;124m'\u001b[39m: movie\u001b[38;5;241m.\u001b[39mxpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.//div[contains(@class, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeter-const-ranking\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)]/span/text()\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     20\u001b[0m     }\n\u001b[0;32m     21\u001b[0m     all_movies\u001b[38;5;241m.\u001b[39mappend(m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(all_movies)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "from lxml import html\n",
    "\n",
    "ua = UserAgent()\n",
    "url = 'https://www.imdb.com/chart/moviemeter/?ref_=nv_mv_mpm'\n",
    "headers = {'User-Agent': ua.random}\n",
    "session = requests.Session()\n",
    "response = session.get(url, headers=headers)\n",
    "tree = html.fromstring(html=response.content)\n",
    "movies = tree.xpath(\".//div[contains(@class, 'cli-title')]\")\n",
    "all_movies = []\n",
    "for movie in movies:\n",
    "    m = {\n",
    "    'name': movie.xpath(\".//div[contains(@class, 'cli-title')]/a/h3/text()\")[0],\n",
    "    'release_year': movie.xpath(\".//div[contains(@class, 'cli-title-metadata')]/span/text()\")[0],\n",
    "    'position': movie.xpath(\".//div[contains(@class, 'meter-const-ranking')]/text()\")[0],\n",
    "    'titlemeter': movie.xpath(\".//div[contains(@class, 'meter-const-ranking')]/span/svg[contains(@class, 'sc-db6887cf-0')]/@class\")[0],\n",
    "    'position_change': movie.xpath(\".//div[contains(@class, 'meter-const-ranking')]/span/text()\")[0]\n",
    "    }\n",
    "    all_movies.append(m)\n",
    "print(all_movies)\n",
    "print(len(all_movies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Сохранение данных в MongoDB\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m movie \u001b[38;5;129;01min\u001b[39;00m movies:\n\u001b[1;32m---> 33\u001b[0m     title \u001b[38;5;241m=\u001b[39m \u001b[43mmovie\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxpath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/div//h3[@class=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mipc-title__text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# year = movie.xpath('.//td[@class=\"titleColumn\"]/span/text()')[0]\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     rating \u001b[38;5;241m=\u001b[39m movie\u001b[38;5;241m.\u001b[39mxpath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/div//span[@class=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipc-rating-star--rating\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "from lxml import html\n",
    "from pymongo import MongoClient\n",
    "ua = UserAgent()\n",
    "url = 'https://www.imdb.com/chart/moviemeter/?ref_=nv_mv_mpm'\n",
    "headers = {'User-Agent': ua.random}\n",
    "session = requests.Session()\n",
    "\n",
    "\n",
    "\n",
    "# URL страницы IMDb\n",
    "# url = \"https://www.imdb.com/chart/moviemeter/?ref_=nv_mv_mpm\"\n",
    "\n",
    "# Отправка GET-запроса\n",
    "# response = requests.get(url)\n",
    "response = session.get(url, headers=headers)\n",
    "response.raise_for_status()  # Проверка на ошибки\n",
    "print(response.status_code)\n",
    "# Парсинг HTML\n",
    "tree = html.fromstring(response.content)\n",
    "\n",
    "# Извлечение данных о фильмах\n",
    "movies = tree.xpath('//ul[contains(@class,\"ipc-metadata-list\")]/li')\n",
    "\n",
    "# Подключение к MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['imdb_database']  # Название базы данных\n",
    "collection = db['movies']  # Название коллекции\n",
    "\n",
    "# Сохранение данных в MongoDB\n",
    "for movie in movies:\n",
    "    title = movie.xpath('/div//h3[@class=\"ipc-title__text\"]')[0]\n",
    "    # year = movie.xpath('.//td[@class=\"titleColumn\"]/span/text()')[0]\n",
    "    rating = movie.xpath('import requests\n",
    "from fake_useragent import UserAgent\n",
    "from lxml import html\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def get_random_user_agent():\n",
    "    ua = UserAgent()\n",
    "    return ua.random\n",
    "\n",
    "def send_get_request(url, headers):\n",
    "    session = requests.Session()\n",
    "    response = session.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response\n",
    "\n",
    "def parse_html(response):\n",
    "    tree = html.fromstring(response.content)\n",
    "    return tree\n",
    "\n",
    "def extract_movie_data(tree):\n",
    "    movies = tree.xpath('//ul[contains(@class,\"ipc-metadata-list\")]/li')\n",
    "    return movies\n",
    "\n",
    "def connect_to_mongodb():\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    db = client['imdb_database']\n",
    "    collection = db['movies']\n",
    "    return collection\n",
    "\n",
    "def save_movie_data(collection, movie):\n",
    "    title = movie.xpath('/div//h3[@class=\"ipc-title__text\"]')[0]\n",
    "    rating = movie.xpath('/div//span[@class=\"ipc-rating-star--rating\"]')[0]\n",
    "    movie_data = {\n",
    "        'title': title.text,\n",
    "        'rating': rating.text\n",
    "    }\n",
    "    collection.insert_one(movie_data)\n",
    "\n",
    "def main():\n",
    "    url = 'https://www.imdb.com/chart/moviemeter/?ref_=nv_mv_mpm'\n",
    "    headers = {'User-Agent': get_random_user_agent()}\n",
    "    response = send_get_request(url, headers)\n",
    "    tree = parse_html(response)\n",
    "    movies = extract_movie_data(tree)\n",
    "    collection = connect_to_mongodb()\n",
    "    for movie in movies:\n",
    "        save_movie_data(collection, movie)\n",
    "    print(\"Данные успешно сохранены в MongoDB.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()/div//span[@class=\"ipc-rating-star--rating\"]')[0]\n",
    "    print(title.text)\n",
    "    print(rating.text)\n",
    "    # Создание документа\n",
    "    movie_data = {\n",
    "        'title': title,\n",
    "        # 'year': year,\n",
    "        # 'rating': rating\n",
    "    }\n",
    "    # print(movie_data)\n",
    "    # Вставка в коллекцию\n",
    "    # collection.insert_one(movie_data)\n",
    "\n",
    "print(\"Данные успешно сохранены в MongoDB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Данные успешно сохранены в MongoDB.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "from lxml import html\n",
    "from pymongo import MongoClient\n",
    "ua = UserAgent()\n",
    "url = 'https://www.imdb.com/chart/moviemeter/?ref_=nv_mv_mpm'\n",
    "headers = {'User-Agent': ua.random}\n",
    "session = requests.Session()\n",
    "\n",
    "\n",
    "\n",
    "# URL страницы IMDb\n",
    "# url = \"https://www.imdb.com/chart/moviemeter/?ref_=nv_mv_mpm\"\n",
    "\n",
    "# Отправка GET-запроса\n",
    "# response = requests.get(url)\n",
    "response = session.get(url, headers=headers)\n",
    "response.raise_for_status()  # Проверка на ошибки\n",
    "print(response.status_code)\n",
    "\n",
    "# Парсинг HTML\n",
    "tree = html.fromstring(response.content)\n",
    "\n",
    "# Извлечение данных о фильмах\n",
    "movies = tree.xpath('//table[@class=\"chart\"]/tbody/tr')\n",
    "\n",
    "# Подключение к MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['imdb_database']  # Название базы данных\n",
    "collection = db['movies']  # Название коллекции\n",
    "\n",
    "# Сохранение данных в MongoDB\n",
    "for movie in movies:\n",
    "    title = movie.xpath('.//td[@class=\"titleColumn\"]/a/text()')\n",
    "    year = movie.xpath('.//td[@class=\"titleColumn\"]/span/text()')\n",
    "    rating = movie.xpath('.//td[@class=\"ratingColumn imdbRating\"]/strong/text()')\n",
    "    \n",
    "    if title and year and rating:  # Проверка на наличие данных\n",
    "        movie_data = {\n",
    "            'title': title[0],\n",
    "            'year': year[0],\n",
    "            'rating': rating[0]\n",
    "        }\n",
    "        print(movie_data)\n",
    "        # Вставка в коллекцию\n",
    "        collection.insert_one(movie_data)\n",
    "\n",
    "print(\"Данные успешно сохранены в MongoDB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "Ошибка при парсинге данных фильма: list index out of range\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def scrape_imdb_moviemeter():\n",
    "    url = \"https://www.imdb.com/chart/moviemeter/?ref_=nv_mv_mpm\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3' # Замените на ваш User-Agent\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status() # Проверка на ошибки HTTP\n",
    "        tree = html.fromstring(response.content)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Ошибка при запросе к IMDb: {e}\")\n",
    "        return None\n",
    "\n",
    "    movies = []\n",
    "    for movie in tree.xpath('//div[contains(@class, \"cli-title\")]'):\n",
    "        try:\n",
    "            title = movie.xpath(\".//div[contains(@class, 'cli-title')]/a/h3/text()\")[0].strip()\n",
    "            print(title)\n",
    "            year = int(movie.xpath(\".//div[contains(@class, 'cli-title-metadata')]/span/text()\")[0].strip()[1:-1]) # Извлекаем год из скобок\n",
    "            rating = float(movie.xpath(\".//div[contains(@class, 'meter-const-ranking')]/text()\")[0].strip())\n",
    "            # ... здесь можно добавить извлечение других данных (например, режиссера, актеров) ...\n",
    "            movies.append({\n",
    "                \"title\": title,\n",
    "                \"year\": year,\n",
    "                \"rating\": rating\n",
    "                # ... другие поля ...\n",
    "            })\n",
    "        except (IndexError, ValueError) as e:\n",
    "            print(f\"Ошибка при парсинге данных фильма: {e}\") # Обработка ошибок при парсинге\n",
    "\n",
    "\n",
    "    return movies\n",
    "\n",
    "\n",
    "def save_to_mongodb(movies):\n",
    "    client = MongoClient(\"mongodb://localhost:27017/\") # Замените на ваши данные подключения\n",
    "    db = client[\"imdb\"] # имя базы данных\n",
    "    collection = db[\"moviemeter\"] # имя коллекции\n",
    "\n",
    "    try:\n",
    "        if movies:\n",
    "            collection.insert_many(movies) # вставка нескольких документов\n",
    "            print(f\"Данные успешно сохранены в MongoDB.\")\n",
    "        else:\n",
    "            print(\"Нет данных для сохранения.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при сохранении данных в MongoDB: {e}\")\n",
    "    finally:\n",
    "        client.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    imdb_data = scrape_imdb_moviemeter()\n",
    "    print(imdb_data)\n",
    "    if imdb_data:\n",
    "        save_to_mongodb(imdb_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<Element html at 0x1ee8d1a3660>\n",
      "74\n",
      "['Живые восковые черви, восковые черви рыбалка, кормушки для рептилий, бесплатная доставка', 'Живые гигантские личинки насекомых бесплатная доставка живой прибытия гарантия', 'Живые шипы, личинки синяя бутылка мухи личинки Бесплатная доставка, живая гарантия', 'Apple iPhone Pro 2-го поколения с чехлом для беспроводной зарядки MagSafe — США', 'Apple iPhone Pro 2-го поколения с чехлом для беспроводной зарядки MagSafe — (USB-C) — США', 'Светодиодный фонарик перчатки USB перезаряжаемый руки бесплатно удобный палец свет перчатки', 'Oros ® Strike индикатор 3-Pack * новый 2025 запас * BUNGS для рыбалки нахлыстом', 'Мощность вертлюги размер 5 8 10 удивительный прочность-кол X 50', 'Apple iPhone Pro 2-го поколения с чехлом для беспроводной зарядки MagSafe — (USB-C) — США', 'Суперзащитная маска на все лицо противотуманный экран безопасный прозрачный чехол на голову сделано в США', 'Рыболовная леска Zebco Omniflex Monofilament, 20 фунтов протестирована бесплатная доставка', 'ЖАБА FROGMORE КРЕВЕТКИ ОЧИСТИТЕЛЬ', 'Перезаряжаемый фонарик перчатки перчатки без пальцев светодиодное освещение ремонт палец лампа', 'Шкив перьевые установки x 5 - качественные береговые установки - грунтовые буровые установки Cod 2/0', 'Плетеная леска Beyond Braid — износостойкая — не растягивается — прочная', 'Плетеная леска/оплетка Reaction Tackle — 4 и 8 нитей цвета мха', 'для Apple iPhone Pro 2-го поколения правые левые капсулы с чехлом для беспроводной зарядки сделано в США', 'Скоростные зажимы Topwater Co', 'Сверхдержавой море плетеная леска 328/547/1093 ярдов полиэтилен 4/8 пряди 12-100 фунтов', '500pcs рыболовные крючки 10 размера черные серебряные рыболовные заточенные с коробкой качество комплект', '1 пара перчаток со светодиодным фонариком для рыбалки на открытом воздухе кемпинга походных перчаток мужские женские', 'Whopper Plopper Topwater рыболовные приманки бас приманка плавающий вращающийся хвост', \"Pro-Tec порошковая краска выбор цвета-джига и ложка краска 2 унций (примерно 56.70 г.) (TJ 's Tackle)\", 'Скамейки петли для приютов для подледной рыбалки OTTER Flipover', '4 шт электронных светодиодных рыболовных фонаря звуковая сигнализация оповещение колокол зажим на удочку', 'Apple iPhone Pro 2-го поколения с чехлом для беспроводной зарядки MagSafe', 'Новый Apple iPhone Pro 2-го поколения с MagSafe беспроводной зарядки чехол', 'Падение грузила черный ил камуфляж 3G, 5g, 7g, нетоксичной неэтилированный рыбачат наркоман Великобритания', 'Силиконовый полюс поплавок резина, 1 метр длины, 4 размеров, от Nick Gilbert поплавок', '6/8/10/12/16 футов рыболовная литая сеть приманка легко бросать вручную литая прочная нейлоновая сетка США', '4 × уличный ночник водонепроницаемые перчатки для рыбалки со светодиодным фонариком спасения инструменты', 'Deps Midst Jig Head Weedless Mid Bottom Hover Strolling (выберите вес) JDM', 'Вставка NG Glow Top Loaded Wagglers от Nick Gilbert Floats', 'Рубашка USGI Polartec желтовато-коричневая пустынная средний вес L2 поколение III вафельная сетка для холодной погоды', 'Мощность зажимы, быстрые зажимы, скорости, зажимы, защелки для рыбалки 50 фунтов (примерно 22.68 кг) или 125 фунтов (примерно 56.70 кг) прочность', '8/10/12/14/16FT рыболовная накидная сеть приманки легко бросить отлитая крепкой нейлоновой сетки Usa', 'Ловушка для малых крабов удочка для ловли крабов крабов каменных крабов упаковка 2 шт.', 'Deps Sakamata Shad 5 дюймов мягкая пластиковая приманка Fluke в наличии из Японии', 'DEPS SAKAMATA SHAD 5 ДЮЙМОВ FLUKE ВЫБЕРИТЕ ЦВЕТ JDM ЯПОНИЯ HOVER ПРОГУЛКИ LARGEMOUT', 'Рыболовные мушки для ловли рыбы нахлыстом Adams Parachute Dry — одна дюжина — доступные размеры', 'Deps Sakamata Shad 4 5 6 7 8 дюймов JDM выберите цвет/середину прогулки навес прогулки', 'Kylebooker WF1F-8F плавающая рыболовная леска с передним весом дизайн с сварной петлей', 'УФ защита лицевая маска шарф-труба шарф ветрозащитная дышащая бандана подшлемник', '250 живых восковых червей / пчелиная моли / птица / рептилия, были производителями БЕСПЛАТНАЯ ДОСТАВКА', 'Рыболовные приманки 200x из нержавеющей стали с разделенными кольцами размер 5 для рыболовного защелкивающегося соединителя', 'Матовые поляризованные линзы Costa Del Mar Rinconcito с черной оправой/серым градиентом 580P', 'Портативный дорожный цифровой подвесной чемодан в виде рыбы с жидкокристаллическим дисплеем электронный 110 фунтов / 50 кг', 'Индикатор удара Oros упаковка 6 шт.', 'FJUKA крючок WAFTERS пополнить пакеты в 4 мм, 6 мм, 8 мм и 11 мм - рыболовная приманка', 'Danville ПЛОСКАЯ ВОСКОВАЯ НИТЬ 210 ДЕНЬЕ 100 ярдов катушка завязывание мух и приспособлений', 'Суперзащитная маска на все лицо противотуманный экран безопасный прозрачный чехол на голову', 'Стандартный плавать джиг танцор лезвия, шейк спиннер лезвия, Mag джиг танцор лезвие', 'Катушечная смазка Penn Precision', 'Мягкая пластиковая джеркбейт Deps Sakamata Shad Fluke 4 дюйма, 5 дюймов, 6 дюймов, 7 дюймов, 8 дюймов', 'Labwork X-Tube термоусадочная пленка трубки для рукояток стержней 14 размеров 5 цветов 39 дюймов и 64 дюйма', 'Корпуса попперов/слайдеров с двойным стволом - для рыбалки нахлыстом', 'FISH N CHIX КАЛЕНДАРЬ 2025', 'Bank грузила / 10 фунтов лот от 1 до 20 унций с бесплатной ускоренной доставкой!', '2X BAIT NEEDLE, EXTRA LONG,16CM,HOOK TYPE NEEDLES,SLIM NEEDLE,HEAVY', '500000Lumens светодиодный свет глубоководной подводной лодки рыболовная приманка светодиод рыбы лампа', 'Термоусадочные трубки X-Tube для ручек стержней — 5 цветов 14 размеров длина 39 дюймов и 64 дюйма', 'Рыбалка на окуня Shimano St Baby Ayu BANTAM LIGEN FLASH BOOST (5VZRT66W07)', 'Рукоятки EVA для строительства стержней, рукоделия, все новые цвета!!!', 'Джиги Shimano Butterfly Flat-Fall', 'Супербезопасный джиг Hoffman для обоих режимов срабатывания', 'Рыболовная нахлыстовая тако (3 упаковки)', 'Rapala Heavy-Duty Electric Fillet Knife Combo Set with Storage Case (R12HDRF)', 'Portable Aluminum Alloy 24 Rods Rack Fishing Rod Pole Holder Stand Storage Tool', 'unopened DEPS DEPS Sakamata Shad 6 inch # 127 Silver Shad 2 set', 'Penn 2OZGSESD12 Reel Grease - 1 lb', 'Eagle Claw Ice Rod Case With 4 Foam Inserts WMRODCASE1', 'ANDE Leader Wrist Spool Clear 40lb 50 Yards Pcw500040', 'Низкопрофильная катушка Abu Garcia REVO4 Revo X, 6,6:1 для правосторонней стойки, подшипники 7+1', 'Garmin Gt52Hw-Tm High Wide Chirp Downvu/Sidevu 12 контактов', 'Lowrance HDS-9 PRO с активной визуализации 3-в-1 преобразователь 000-15981-001', 'Lowrance крючок раскрыть 9 американских внутренних озер и tripleshot преобразователь 000-15526-001', 'Garmin GT56UHD-TM Ultra HD сканирование сонара все-в-одном преобразователь 010-13073-00', 'Фторуглеродная леска Sunline FC Sniper (JDM-Far Superior to US Version)', 'Мягкая пластиковая джеркбейт Deps Sakamata Shad Fluke 4 дюйма, 5 дюймов, 6 дюймов, 7 дюймов, 8 дюймов', 'Низкопрофильная катушка Abu Garcia REVO4 Revo X, 6,6:1 для правосторонней стойки, подшипники 7+1', 'Garmin Gt52Hw-Tm High Wide Chirp Downvu/Sidevu 12 контактов', 'Преобразователь Humminbird, Mega 360 изображения, для Ultrex 411250-1 новый в коробке', 'Тройные крючки 10/0 коробка из 36, бронза. качество. защемление, аллигаторы, троллинг и т.д.;', 'Джеркбейт Megabass Vision Oneten 110', 'Penn 2OZGSESD12 Reel Grease - 1 lb', 'Portable Aluminum Alloy 24 Rods Rack Fishing Rod Pole Holder Stand Storage Tool', 'Rapala Heavy-Duty Electric Fillet Knife Combo Set with Storage Case (R12HDRF)']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[173], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m prises_info \u001b[38;5;241m=\u001b[39m [el\u001b[38;5;241m.\u001b[39mtext_content()\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m prises]\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# print(len(prises_info))\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m info \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mxpath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.//span[contains(@class, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# print(len(info))\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "from pprint import pprint\n",
    "# Определение целевого URL\n",
    "url = \"\"\n",
    "\n",
    "\n",
    "ua = UserAgent()\n",
    "# ua = {}\n",
    "url = 'https://www.ebay.com'\n",
    "headers = {'User-Agent': ua.safari}\n",
    "# headers = {'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'}\n",
    "session = requests.Session()\n",
    "all_books = []\n",
    "page = \"/b/Fishing-Equipment-Supplies/1492/bn_1851047\"\n",
    "response = session.get(url + page, headers=headers)\n",
    "print(response.status_code)\n",
    "dom = html.fromstring(response.text)\n",
    "print(dom)\n",
    "items_list = []\n",
    "items = dom.xpath('//li[contains(@class, \"brwrvr__item-card brwrvr__item-card--list\")]')\n",
    "print(len(items))\n",
    "for item in items:\n",
    "    items_info = {}\n",
    "    names = dom.xpath('.//h3[contains(@class, \"textual-display\")]')\n",
    "    # print(names) # Выводит список текстов\n",
    "\n",
    "    # # Извлекаем текст из каждого элемента\n",
    "    name_info = [el.text_content().strip() for el in names]\n",
    "    print(name_info)\n",
    "    time.sleep(5)\n",
    "    # links = dom.xpath('//h3[contains(@class, \"textual-display\")]/../@href')\n",
    "    links = item.xpath('.//h3[@class=\"textual-display bsig__title__text\"]/../@href')\n",
    "    # print(len(links))\n",
    "    # print(links)\n",
    "    time.sleep(3)\n",
    "    prises = item.xpath('.//span[contains(@class, \"textual-display bsig__price bsig__price--displayprice\")]')\n",
    "    prises_info = [el.text_content().strip() for el in prises]\n",
    "    # print(len(prises_info))\n",
    "    time.sleep(3)\n",
    "    info = item.xpath('.//span[contains(@class, \"negative\")]')\n",
    "    # print(len(info))\n",
    "    add_info = [el.text_content().strip() for el in info]\n",
    "    # print(add_info)\n",
    "    items_info['name_info'] = name_info\n",
    "    items_info['links'] = links\n",
    "    items_info['prises_info'] = prises_info\n",
    "    items_info['add_info'] = add_info\n",
    "    items_list.append(items_info)\n",
    "pprint(items_list)\n",
    "\n",
    "\n",
    "# //time/ancestor::*[contains(@class, '_topnews')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
